{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98c6210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "# Because we have runned the code multiple times\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot pretty:\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from feature_engine import encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b95a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: \n",
      " sample size:  57011 \n",
      " feature size:  219\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"rawData_final.csv\")\n",
    "def get_shape(data):\n",
    "    print(\"Shape of data: \\n\"\n",
    "        \" sample size: \", data.shape[0], \n",
    "        \"\\n feature size: \" , data.shape[1])\n",
    "get_shape(rawData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202526e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates (excl. the kept):  12206\n",
      "Shape of data: \n",
      " sample size:  44805 \n",
      " feature size:  219\n",
      "Removing non-fri handel:  4841\n",
      "Shape of data: \n",
      " sample size:  39964 \n",
      " feature size:  219\n"
     ]
    }
   ],
   "source": [
    "bolean_raw = rawData.duplicated(subset = 'address.gstKvhx', keep = 'last')\n",
    "print(\"Number of duplicates (excl. the kept): \", len(bolean_raw[bolean_raw == True ]))\n",
    "housing_data = rawData[bolean_raw == False]\n",
    "\n",
    "get_shape(housing_data)\n",
    "bolean_friHandel = housing_data['address.latestSale.saleType'] == 'Fri handel'\n",
    "print(\"Removing non-fri handel: \", len(bolean_friHandel[bolean_friHandel == False]))\n",
    "housing_data = housing_data[bolean_friHandel == True]\n",
    "\n",
    "housing_data.replace('-', np.nan, inplace=True)\n",
    "housing_data.replace(' - ', np.nan, inplace=True)\n",
    "\n",
    "housing_data.head()\n",
    "\n",
    "housing_data_idx = housing_data.reset_index()\n",
    "\n",
    "get_shape(housing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a6a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_num_housing = ['salePrice_b', 'paymentCash_b',\n",
    "       'AVM_pris_d', 'propertyValuation_b',\n",
    "       'alfs_areaWeighted', 'buildYear_b', 'radonRiskCategory_d',\n",
    "       'salesYear_b','Boligstørrelse', 'alfs_area', \n",
    "       'alfs_areaBasement', 'Kælder',\n",
    "       'Vægtet Areal',\n",
    "       'alfs_numberOfRooms', 'Antal værelser','alfs_buildYear_d',\n",
    "       'propertyCharges',\n",
    "       'alfs_postal', \n",
    "       'salesPeriod', 'address.latestForSale.dateAnnounced', \n",
    "       'address.latestForSale.dateAdded', \n",
    "       'address.latestForSale.dateRemoved', \n",
    "       'address.latestForSale.salesPeriodTotal',\n",
    "       'areaResidential_b',\n",
    "       'numberOfFloors_b', 'floor_b',\n",
    "       'alfs_rebuildYear', 'Opførselsesår', \n",
    "       'Antal Etager', 'numberOfToilets_bd', 'numberOfBaths_bd',\n",
    "       'turnoutVote_d', 'daycare_h',\n",
    "       'doctor_h', 'hospital_h', 'junction_h', 'metro_h', 'school_h',\n",
    "       'busstop_h', 'strain_h', 'supermarket_h', 'train_h', 'library_h',\n",
    "       'pharmacy_h', 'coast_h', 'forest_h', 'lake_h', 'airport_h',\n",
    "       'sportshall_h', 'publicbath_h', 'soccerfield_h', 'roadtrain_h',\n",
    "       'priceIndex_s', 'priceChangeMPriorIndex_s', 'priceChangeYPriorIndex_s',\n",
    "       'latitude_b', 'longitude_b',\n",
    "       'Ombygningsår', 'rebuildYear_b',\n",
    "        'breakInStatistic',\n",
    "        'WaterHardness',\n",
    "        \"unemploymentRateCPH_s\", \"unemploymentRateDK_s\", \"mortgageRate_s\", \"OMXC20_s\",\n",
    "                  \"Bygning, Samlet areal\", \"aboveSea_d\"]\n",
    "\n",
    "\n",
    "cat_features = ['postalId_b', 'usage_d', 'outerwall_d', 'roof_d', \n",
    "                'heating_d', 'biggestParty_d', 'noise_d','energyMark_b', \n",
    "                'radonRisk_d', 'floodingRisk_d', 'quarter_b', 'quarter0_b', \n",
    "                'kitchen.content_d', 'itemTypeName_b', 'itemtypeName', \"city_b\", \"electionArea_d\"]\n",
    "\n",
    "removed_features = [\"address.gstKvhx\",\"municipalityNumber_b\",\"address.oisPropertyNumber\",\"address_b\",\n",
    "\"street_b\",\"streetName_b\",\"address.itemType\",\n",
    "\"address.itemTypeNumber\",\"address.mapPosition.hasCoordinates\",\"address.wishPropertyLocationLink\",\n",
    "\"address.hasEnergyMark\",\"address.energyMark\",\"address.energyMarkLink\",\n",
    "\"address.environmentData.soilContamination\",\"address.environmentData.serviceStatus.renewTicket\",\n",
    "\"address.environmentData.serviceStatus.errorCode\",\"address.environmentData.serviceStatus.errorText\",\n",
    "\"address.environmentData.serviceStatus.errorId\",\n",
    "\"address.latestValuation.valuationYear\",\"address.latestValuation.valuationDate\",\n",
    "\"valuationDate_b\",\"address.latestValuation.farmhouseParcelValuation\",\n",
    "\"address.latestValuation.farmhousePropertyValuation\",\n",
    "\"address.latestSale.saleTypeId\",\n",
    "\"address.latestForSale.id\",\"address.latestForSale.propertyNumberAgent\",\"address.latestForSale.addressId\",\n",
    "\"address.latestForSale.isArchive\",\"address.latestForSale.uniqueNumber\",\n",
    "\"address.latestForSale.description\",\"address.latestForSale.descriptionHeadline\",\n",
    "\"address.latestForSale.priceDevelopment\" ,\"address.latestForSale.priceDevelopmentHistoric\",\n",
    "\"address.latestForSale.usageExpenses\",\"address.latestForSale.paymentGross\",\n",
    "\"address.latestForSale.paymentNet\",\"address.latestForSale.paymentExpenses\",\"address.latestForSale.itemType\",\n",
    "\"address.latestForSale.itemTypeNumber\",\"address.latestForSale.marketingItemType\",\"address.latestForSale.address\",\n",
    "\"address.latestForSale.streetName\",\"address.latestForSale.houseNumber\",\"address.latestForSale.city\",\n",
    "\"address.latestForSale.placeName\",\"address.latestForSale.placeNameSeparator\",\n",
    "\"address.latestForSale.imageLink600X400\",\n",
    "\"address.latestForSale.canShowSalesPeriodTotal\",\n",
    "\"address.latestForSale.areaParcel\",\n",
    "\"address.latestForSale.areaWeightedAsterix\",\"address.latestForSale.areaWeightedTitleMessage\",\n",
    "\"address.latestForSale.areaWeightedKrM2Title\",\n",
    "\"address.latestForSale.agentChainName\",\"address.latestForSale.agentId\",\n",
    "\"address.latestForSale.agentsLogoLink\",\n",
    "\"address.latestForSale.propertyLink\",\"address.latestForSale.redirectLink\",\n",
    "\"address.latestForSale.floorName\",\"address.latestForSale.memberOfDe\",\n",
    "\"address.latestForSale.hasEnergyMark\",\"address.latestForSale.energyMarkLink\",\n",
    "\"address.latestForSale.hasOpenHouse\",\n",
    "\"address.latestForSale.nextOpenHouse\",\n",
    "\"address.latestForSale.nextOpenHouseShort\",\"address.latestForSale.nextOpenHouseSignup\",\n",
    "\"address.latestForSale.municipalityNumber\",\n",
    "\"address.latestForSale.oisPropertyNumber\",\"address.latestForSale.isFavorite\",\"address.latestForSale.hasComment\",\n",
    "\"address.latestForSale.comment\",\n",
    "\"address.latestForSale.rentalLink\",\"address.latestForSale.linkDomain\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData\",\"address.latestForSale.mapPosition.hasCoordinates\",\n",
    "\"address.latestForSale.mapPosition.latLng.lat\",\"address.latestForSale.mapPosition.latLng.lng\",\n",
    "\"address.latestForSale.videoRedirectLink\",\"address.latestForSale.openHouseRedirectLink\",\n",
    "\"address.latestForSale.projectSale\",\n",
    "\"address.latestForSale.kvhx\",\"address.latestForSale.gstKvhx\",\"address.latestForSale.wishPropertyLocationLink\",\n",
    "\"address.latestForSale.hasRentalLink\",\"address.latestForSale.hasVideoLink\",\n",
    "\"address.latestForSale.rating.ratings.conditionRating\",\n",
    "\"address.latestForSale.rating.ratings.kitchenRating\",\"address.latestForSale.rating.ratings.locationRating\",\n",
    "\"address.latestForSale.rating.ratings.bathRating\",\n",
    "\"address.latestForSale.rating.averageRating\",\"address.latestForSale.rating.roundAverageRating\",\n",
    "\"address.latestForSale.oisHidden\",\"address.latestForSale.nextOpenHouseTime\",\n",
    "\"address.latestForSale.calculateLoanAgentChain\",\"address.latestForSale.label\",\"address.latestForSale\",\n",
    "\"address.latestValuation\",\"address.environmentData.breakInStatistic\",\"address.latestForSale.mapPosition.latLng\",\n",
    "\"address.mapPosition.latLng\",\"dingeo_link\",\n",
    "\"address.latestSale\",\"address.latestForSale.propertyPartiallyOwnedFinancialData.purchasePrice\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.maximumPriceRatio\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.maximumPrice\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.housingAssociationDebtShare\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.housingAssociationDebt\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.financingInformation\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.expenseNet\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.expenseGross\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.estimatedTechnicalPrice\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.estimatedTechnicalAreaPrice\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.downPayment\",\n",
    "\"address.latestForSale.propertyPartiallyOwnedFinancialData.distributionRatio\",\n",
    "\"Unnamed: 0\", \"address.latestForSale.hasAreaWeighted\",\n",
    "\"address.latestSale.saleType\", \"saleDate_b\",\"saleDate_b.1\", \"previousMonth\",\n",
    "                   \"Bevaringsværdig\", \"Energimærke\", \"Fredning\",\n",
    "                   \"Location\", \n",
    "                   \"address.latestForSale.areaPaymentCash\",\n",
    "                    \"address.latestForSale.downPayment\",\n",
    "\"address.latestValuation.parcelValuation\",\n",
    "        \"address.environmentData.breakInStatistic.countryAverage\",\n",
    "        \"address.environmentData.breakInStatistic.countyAverage\",\n",
    "        \"address.environmentData.breakInStatistic.riskCategory\",\n",
    "        'priceHouse', 'priceChangeMHouse', 'priceChangeYHouse',\n",
    "       'priceApartment', 'priceChangeMApart', 'priceChangeYApart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e4c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_dropped = X.drop(self.variables, axis = 1)\n",
    "        return X_dropped\n",
    "    \n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.loc[:,self.variables]\n",
    "\n",
    "class paymentAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables \n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        \n",
    "        replace_func = np.vectorize(lambda x: float(x.replace('.','')))\n",
    "        \n",
    "        rep_X = replace_func(X_.astype(str))\n",
    "        X_transformed = pd.DataFrame(rep_X, \n",
    "                         columns = self.variables)\n",
    "\n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        X__[self.variables] = X_transformed[self.variables].values\n",
    "        return X__\n",
    "        \n",
    "\n",
    "pay_vars = ['salePrice_b', 'paymentCash_b', \n",
    "            'AVM_pris_d', 'propertyValuation_b']\n",
    "\n",
    "class itemAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        \n",
    "        array_X = np.array(X_)\n",
    "        itemType = np.where((array_X[:, 0] == 'Ejerlejlighed') | \\\n",
    "                            (array_X[:, 0] == 'Rækkehus') | \\\n",
    "                            (array_X[:, 0] == 'Villa') & \\\n",
    "                            (array_X[:, 1] != 'Andelsbolig'), \n",
    "                            array_X[:, 0], np.nan)\n",
    "        \n",
    "        X_transformed = pd.DataFrame(itemType, \n",
    "                         columns = [self.variables[0]])\n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[self.variables[0]] = X_transformed.values\n",
    "        return X__\n",
    "        \n",
    "item_vars = ['itemTypeName_b', 'itemtypeName']   \n",
    "\n",
    "\n",
    "\n",
    "class interiorAttributesAdder2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        \n",
    "        replace_func = np.vectorize(lambda x: float(x.replace(' m2','')))\n",
    "        replace_func2 = np.vectorize(lambda x: float(x.replace('nan','0')))\n",
    "        replace_func3 = np.vectorize(lambda x: float(x.replace(' meter','')))\n",
    "        \n",
    "        #rep_X = []\n",
    "        #for i in self.variables:\n",
    "        rep_X = replace_func2(replace_func(X_.loc[:,self.variables[:9]].astype(str)).astype(str))\n",
    "        \n",
    "        where0_X = np.where(rep_X[:, 1] == 'number', rep_X[:, 1], rep_X[:, 0])\n",
    "        \n",
    "        basement = np.where(rep_X[:, 2] == 'number',rep_X[:, 2], rep_X[:, 3])\n",
    "        where1_X = np.where(basement < 500, \n",
    "                            basement, np.nan) #2:basement, 3: kælder\n",
    "       \n",
    "        where2_X = np.where(rep_X[:, 5] != 0, rep_X[:, 5], rep_X[:, 4]) \n",
    "        where3_X = np.where(rep_X[:, 6] == 'number',rep_X[:, 6], rep_X[:, 7])\n",
    "        \n",
    "        where4_X = rep_X[:, 8]\n",
    "        where5_X = replace_func3(X_.loc[:, self.variables[9]].astype(str))\n",
    "        \n",
    "        where6_X = np.where((X_.loc[:, self.variables[10]] < 0) | (X_.loc[:, self.variables[10]] > 10), \n",
    "                            np.nan, X_.loc[:, self.variables[10]])\n",
    "        \n",
    "        concat_X = np.transpose([where0_X, where1_X, where3_X, where4_X, where5_X, where6_X]) #where2_X, \n",
    "        \n",
    "    \n",
    "        X_transformed = pd.DataFrame(concat_X, \n",
    "                         columns = [self.variables[1], self.variables[2], \n",
    "                                     self.variables[6], #self.variables[5],\n",
    "                                    \"BuildingUnion_area\", self.variables[9],\n",
    "                                    self.variables[10]])\n",
    "\n",
    "\n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[[self.variables[1], \"areaBasement\", \n",
    "             #self.variables[5], \n",
    "             \"numberOfRooms\", \n",
    "             \"BuildingUnion_area\", self.variables[9], self.variables[10]]] = X_transformed.values\n",
    "        return X__\n",
    "\n",
    "inter_vars = ['Boligstørrelse', 'alfs_area', \n",
    "              'alfs_areaBasement', 'Kælder',\n",
    "              'Vægtet Areal', 'alfs_areaWeighted',\n",
    "              'alfs_numberOfRooms', 'Antal værelser', \n",
    "              \"Bygning, Samlet areal\", \n",
    "              \"aboveSea_d\", 'numberOfToilets_bd']  \n",
    "\n",
    "\n",
    "class interiorAttributesAdder2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        \n",
    "        replace_func = np.vectorize(lambda x: float(x.replace(' m2','')))\n",
    "        replace_func2 = np.vectorize(lambda x: float(x.replace('nan','0')))\n",
    "        replace_func3 = np.vectorize(lambda x: float(x.replace(' meter','')))\n",
    "        \n",
    "        rep_X = replace_func2(replace_func(X_.loc[:,self.variables[:8]].astype(str)).astype(str))\n",
    "        \n",
    "        where0_X = np.where(rep_X[:, 1] == 'number', rep_X[:, 1], rep_X[:, 0])\n",
    "        \n",
    "        basement = np.where(rep_X[:, 2] == 'number',rep_X[:, 2], rep_X[:, 3])\n",
    "        where1_X = np.where(basement < 500, \n",
    "                            basement, np.nan) #2:basement, 3: kælder\n",
    "       \n",
    "        where2_X = np.where(rep_X[:, 5] != 0, rep_X[:, 5], rep_X[:, 4]) \n",
    "        where3_X = np.where(rep_X[:, 6] == 'number',rep_X[:, 6], rep_X[:, 7])\n",
    "        \n",
    "        #where4_X = rep_X[:, 8]\n",
    "        where5_X = replace_func3(X_.loc[:, self.variables[8]].astype(str))\n",
    "        \n",
    "        where6_X = np.where((X_.loc[:, self.variables[9]] < 0) | (X_.loc[:, self.variables[9]] > 10), \n",
    "                            np.nan, X_.loc[:, self.variables[9]])\n",
    "        \n",
    "        concat_X = np.transpose([where0_X, where1_X, where3_X, where5_X, where6_X]) # where4_X, where2_X, \n",
    "        \n",
    "    \n",
    "        X_transformed = pd.DataFrame(concat_X, \n",
    "                         columns = [self.variables[1], self.variables[2], \n",
    "                                     self.variables[6], #self.variables[5],\n",
    "                                    #\"BuildingUnion_area\", \n",
    "                                    self.variables[8],\n",
    "                                    self.variables[9]])\n",
    "\n",
    "\n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[[self.variables[1], \"areaBasement\", \n",
    "             #self.variables[5], \n",
    "             \"numberOfRooms\", \n",
    "             #\"BuildingUnion_area\", \n",
    "             self.variables[8], self.variables[9]]] = X_transformed.values\n",
    "        return X__\n",
    "\n",
    "inter_vars2 = ['Boligstørrelse', 'alfs_area', \n",
    "              'alfs_areaBasement', 'Kælder',\n",
    "              'Vægtet Areal', 'alfs_areaWeighted',\n",
    "              'alfs_numberOfRooms', 'Antal værelser', \n",
    "              #\"Bygning, Samlet areal\", \n",
    "              \"aboveSea_d\", 'numberOfToilets_bd'] \n",
    "\n",
    "\n",
    "class rebuildYearAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables): \n",
    "        self.variables = variables\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:, self.variables]\n",
    "        array_X = np.array(X_).astype(float)\n",
    "\n",
    "        \n",
    "        rebuildYear = np.where(array_X[:, 0] > 0, array_X[:, 0], array_X[:, 3])\n",
    "        rebuildYear = np.where(array_X[:, 1] > 0, array_X[:, 1], rebuildYear)\n",
    "        rebuildYear = np.where(array_X[:, 2] > 0, array_X[:, 2], rebuildYear)\n",
    "        rebuildYear = np.where(rebuildYear == 0, np.nan, rebuildYear)\n",
    "        rebuildYear = np.where(rebuildYear < 2022, rebuildYear, np.nan)\n",
    "\n",
    "        buildYear = np.where(array_X[:, 3] == 0, np.nan, array_X[:, 3])\n",
    "        \n",
    "        concat_X = np.transpose([rebuildYear, buildYear])\n",
    "        \n",
    "    \n",
    "        X_transformed = pd.DataFrame(concat_X, \n",
    "                         columns = [self.variables[0], self.variables[3]])\n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[[self.variables[0], self.variables[3]]] = X_transformed.values\n",
    "        return X__\n",
    "        \n",
    "\n",
    "rebuild_vars = ['rebuildYear_b', 'alfs_rebuildYear',\n",
    "               'Ombygningsår', 'buildYear_b']       \n",
    "\n",
    "from datetime import datetime\n",
    "class datetimeAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables \n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        \n",
    "        array_X = np.array(X_)\n",
    "\n",
    "        DateAnnounced = pd.to_datetime(array_X[:, 0], format='%d-%m-%Y', errors='coerce')\n",
    "        DateAdded = pd.to_datetime(array_X[:, 1], format='%d-%m-%Y', errors='coerce')\n",
    "        DateRemoved = pd.to_datetime(array_X[:, 2], format='%d-%m-%Y', errors='coerce')\n",
    "        \n",
    "        AddedRemoved = (DateRemoved - DateAdded).days.astype(float)\n",
    "        AnnouncedRemoved = (DateRemoved - DateAnnounced).days.astype(float)\n",
    "        PeriodTotal = array_X[:,3].astype(float)\n",
    "        Period = array_X[:, 4].astype(float)\n",
    "       \n",
    "        SalesPeriod = np.where(PeriodTotal > 0, PeriodTotal, Period)\n",
    "        SalesPeriod = np.where(SalesPeriod > 0, SalesPeriod, AddedRemoved)\n",
    "        SalesPeriod = np.where(SalesPeriod > 0, SalesPeriod, AnnouncedRemoved)\n",
    "            \n",
    "        X_transformed = pd.DataFrame(SalesPeriod, \n",
    "                         columns = [self.variables[4]])\n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[self.variables[4]] = X_transformed.values\n",
    "        return X__\n",
    "    \n",
    "salePeriod_vars = ['address.latestForSale.dateAnnounced', 'address.latestForSale.dateAdded', \n",
    "                   'address.latestForSale.dateRemoved', 'address.latestForSale.salesPeriodTotal',\n",
    "                   'salesPeriod'] \n",
    "\n",
    "class postalAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        \n",
    "        array_X = np.array(X_)\n",
    "\n",
    "\n",
    "        bins = [0, 1100, 1200, 1300, 1400, 1450, 1500, 1600, 1700, 1800, 1850, 1900, \n",
    "                2000, 2001, 2101, 2151, 2201, 2301, 2401, 2451, 2501, 2701, 2721, 2770] \n",
    "        #The last number is for removal; Kastrup and Hellerup\n",
    "        names = ['<1100', '1100-1200', '1200-1300', '1300-1400','1400-1450', '1450-1500', '1500-1600', \n",
    "                 '1600-1700', '1700-1800', '1800-1850','1850-1900','1900-2000','2000','2100','2150',\n",
    "                 '2200','2300', '2400', '2450', '2500', '2700', '2720', '2720<']\n",
    "        postalId = np.empty((len(X))).astype(str)\n",
    "\n",
    "        num_postalId = np.searchsorted(bins, array_X).astype(int)\n",
    "        for b in range(len(names)):\n",
    "            postalId[num_postalId == (b+1)] = names[b]\n",
    "        postalId = np.where(postalId == '0.0', '2720<', postalId)\n",
    "        postalId = np.where(postalId == '2720<', np.nan, postalId)\n",
    "\n",
    "        \n",
    "        X_transformed = pd.DataFrame(postalId, \n",
    "                         columns = [self.variables])\n",
    "    \n",
    "        X__[self.variables] = X_transformed.values\n",
    "        return X__\n",
    "\n",
    "postal_vars = \"postalId_b\"\n",
    "\n",
    "class energyAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        array_X = np.array(X_)\n",
    "\n",
    "        energyMark = np.empty((len(X))).astype(str)\n",
    "\n",
    "        energyMark = np.where((array_X == \"a1\") | (array_X == \"a2\") | \\\n",
    "                              (array_X == \"a2010\") | (array_X == \"a2015\"),\n",
    "                              \"a\", array_X)\n",
    "        \n",
    "        X_transformed = pd.DataFrame(energyMark, \n",
    "                         columns = [self.variables])\n",
    "    \n",
    "        X__[self.variables] = X_transformed.values\n",
    "        return X__\n",
    "\n",
    "energy_vars = \"energyMark_b\"\n",
    "\n",
    "\n",
    "class usageAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        array_X = np.array(X_)     \n",
    "        usage = np.empty((len(X))).astype(str)\n",
    "\n",
    "\n",
    "        usage = np.where(array_X  == \"Bolig i etageejendom, flerfamiliehus eller to-familiehus\",\n",
    "                         \"Apartment housing\", \"townhouse, chain house, semi-detached house\")\n",
    "        usage = np.where(array_X  == \"Fritliggende enfamiliehus\", \"detached house\", usage)\n",
    "        \n",
    "        X_transformed = pd.DataFrame(usage, \n",
    "                         columns = [self.variables])\n",
    "    \n",
    "        X__[self.variables] = X_transformed.values\n",
    "        return X__\n",
    "\n",
    "\n",
    "usage_vars = \"usage_d\"        \n",
    "\n",
    "\n",
    "class rnfbAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        X__ = X.copy()\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        array_X = np.array(X_)     \n",
    "        \n",
    "        radonRisk = np.where(array_X[:, 0] == \"Meget lav\", \"a Very low\", \"b low\")\n",
    "        radonRisk = np.where(array_X[:, 0] == \"medium\", \"c Medium\", radonRisk)\n",
    "        radonRisk = np.where(array_X[:, 0] == \"høj\", \"d High\", radonRisk)\n",
    "        radonRisk = np.where(array_X[:, 0] == \"meget høj\", \"e Very high\", radonRisk)\n",
    "\n",
    "        noise = np.where(np.where(array_X[:, 1] == \"Mangler\", \"Ingen trafikstøj\", \n",
    "                                  array_X[:, 1]) == \"Ingen trafikstøj\", \"0-55 dB Noiseless\", array_X[:, 1])\n",
    "        noise = np.where(array_X[:, 1] == \"over 75 dB\", \"75 dB or above\", noise)\n",
    "\n",
    "        floodingRisk = np.where(array_X[:, 2] == \"er lav risiko\", \"a Low risk\", \"b Possible risk\")\n",
    "        floodingRisk = np.where(array_X[:, 2] == \"er høj risiko\", \"c High risk\", floodingRisk)\n",
    "\n",
    "        biggestParty = np.where(array_X[:, 3] == \"enhedslisten\", \"a Enhedslisten\", \"b Socialdemokratiet\")\n",
    "        biggestParty = np.where(array_X[:, 3] == \"radikale\", \"c Radikale\", biggestParty)\n",
    "        biggestParty = np.where(array_X[:, 3] == \"venstre\", \"d Vesntre\", biggestParty)\n",
    "\n",
    "        rnfb_X = np.transpose([radonRisk, noise, floodingRisk, biggestParty])\n",
    "        X_transformed = pd.DataFrame(rnfb_X, \n",
    "                        columns = self.variables)\n",
    "    \n",
    "        X__[self.variables] = X_transformed.values\n",
    "  \n",
    "        return X__\n",
    "        \n",
    "\n",
    "rnfb_vars = ['radonRisk_d','noise_d', 'floodingRisk_d', 'biggestParty_d']   \n",
    "\n",
    "\n",
    "class SimpleImputerCustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables, strategy):\n",
    "        self.variables = variables\n",
    "        self.strategy = strategy\n",
    "        self.imp = SimpleImputer(missing_values = np.nan,   \n",
    "                                 strategy = self.strategy)\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.imp.fit(X_)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        X__ = X.copy()\n",
    "        X_transformed = pd.DataFrame(self.imp.transform(X_), \n",
    "                         columns= self.variables)\n",
    "        \n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        X__[self.variables] = X_transformed[self.variables].values\n",
    "        return X__\n",
    "\n",
    "class OutlierRemover(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, variables, factor=1.5):\n",
    "        self.variables = variables\n",
    "        self.factor = factor\n",
    "        \n",
    "    def outlier_detector(self,X,y=None):\n",
    "        X = pd.Series(X).copy()\n",
    "        q1 = X.quantile(0.025)\n",
    "        q3 = X.quantile(0.975)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound.append(q1)# - (self.factor * iqr))\n",
    "        self.upper_bound.append(q3)# + (self.factor * iqr))\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        X_ = pd.DataFrame(X.loc[:, self.variables])\n",
    "        self.lower_bound = []\n",
    "        self.upper_bound = []\n",
    "        X_.apply(self.outlier_detector)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        X_ = pd.DataFrame(X.loc[:, self.variables])\n",
    "        X__ = X.copy()\n",
    "        for i in range(X_.shape[1]):\n",
    "            x = X_.iloc[:, i].copy()\n",
    "            x[(x < self.lower_bound[i]) | (x > self.upper_bound[i])] = np.nan\n",
    "            X__[self.variables[i]] = x\n",
    "           \n",
    "        return X__\n",
    "\n",
    "    \n",
    "class OutlierRemover2(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, variables, factor = 0.025):\n",
    "        self.variables = variables[:-1]\n",
    "        self.areavar = variables[len(variables)-1]\n",
    "        self.factor = factor\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        #X_ = pd.DataFrame(X.loc[:, self.variables[0]])\n",
    "        Xsqr = X.loc[:,self.variables[0]] / X.loc[:,self.areavar]\n",
    "        \n",
    "        q_down = Xsqr.quantile(self.factor)\n",
    "        q_up = Xsqr.quantile(1-self.factor)\n",
    "        \n",
    "        X__ = X.copy()\n",
    "        \n",
    "        X_outlier = np.where((Xsqr < q_down) | (Xsqr > q_up), np.nan, X.loc[:, self.variables[0]] )\n",
    "        X__[self.variables[0]] = X_outlier\n",
    "           \n",
    "        return X__\n",
    "\n",
    "    \n",
    "class MakeToDataFrame(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X__ = pd.DataFrame(X,\n",
    "                          columns = self.variables)\n",
    "        return X__\n",
    "\n",
    "class OneHotEncodercustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "        self.ohe = OneHotEncoder(drop = 'first', handle_unknown = \"error\")\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.ohe.fit(X_)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        X__ = X.copy()\n",
    "        \n",
    "        X_transformed = pd.DataFrame(self.ohe.transform(X_).toarray(),\n",
    "                                    columns = self.ohe.get_feature_names_out())\n",
    "        X__.drop(self.variables, axis = 1, inplace = True)\n",
    "        X__[self.ohe.get_feature_names_out()] = \\\n",
    "            X_transformed[self.ohe.get_feature_names_out()].values\n",
    "        return X__\n",
    "    \n",
    "class OrdinalEncodercustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "        self.od = OrdinalEncoder(handle_unknown = 'error')\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        self.od.fit(X_)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:,self.variables]\n",
    "        X__ = X.copy()\n",
    "        \n",
    "        od_X = self.od.transform(X_)\n",
    "        X_transformed = pd.DataFrame(od_X, \n",
    "                                     columns = self.variables)\n",
    "        \n",
    "        X__.drop(self.variables, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[self.variables] = \\\n",
    "                X_transformed[self.variables].values\n",
    "        return X__\n",
    "    \n",
    "class StandardScalercustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables):\n",
    "        self.variables = variables\n",
    "        self.ss = StandardScaler()\n",
    "    def fit(self, X, y = None):\n",
    "        X_ = X.loc[:, X.columns != self.variables]\n",
    "        self.ss.fit(X_)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.loc[:, X.columns != self.variables]\n",
    "        #columns_list = list(X.columns.difference([self.variables]))\n",
    "        columns_list = list(X.loc[:, X.columns != self.variables].columns)\n",
    "        X__ = X.copy()\n",
    "        \n",
    "        ss_X = self.ss.transform(X_)\n",
    "        X_transformed = pd.DataFrame(ss_X, \n",
    "                                     columns = columns_list)\n",
    "        \n",
    "        X__.drop(columns_list, axis= 1, inplace=True)\n",
    "        \n",
    "        X__[columns_list] = \\\n",
    "                X_transformed[columns_list].values\n",
    "        return X__\n",
    "    \n",
    "    \n",
    "def drop_nans(X, y=None):\n",
    "    total = X.shape[1]                                           \n",
    "    #new_thresh = total - thresh\n",
    "    df = pd.DataFrame(X)\n",
    "    df.dropna(inplace=True) #thresh=new_thresh,\n",
    "    df = np.array(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933b848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape:  (31971, 220)\n",
      "test set shape:  (7993, 220)\n",
      "København S        0.232954\n",
      "København Ø        0.118729\n",
      "Frederiksberg      0.098211\n",
      "Valby              0.077943\n",
      "København K        0.072814\n",
      "København N        0.068185\n",
      "København SV       0.058301\n",
      "København V        0.058301\n",
      "Vanløse            0.054172\n",
      "København NV       0.048542\n",
      "Frederiksberg C    0.048042\n",
      "Brønshøj           0.048042\n",
      "Nordhavn           0.015764\n",
      "Name: city_b, dtype: float64\n",
      "København S        0.232910\n",
      "København Ø        0.118682\n",
      "Frederiksberg      0.098238\n",
      "Valby              0.077920\n",
      "København K        0.072866\n",
      "København N        0.068211\n",
      "København SV       0.058277\n",
      "København V        0.058252\n",
      "Vanløse            0.054124\n",
      "København NV       0.048619\n",
      "Brønshøj           0.048068\n",
      "Frederiksberg C    0.048068\n",
      "Nordhavn           0.015764\n",
      "Name: city_b, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) \n",
    "\n",
    "housing_with_idx = housing_data.reset_index()\n",
    "\n",
    "for train_index, test_index in split.split(housing_with_idx, housing_with_idx['city_b']):\n",
    "        strat_train_set = housing_with_idx.loc[train_index]\n",
    "        strat_test_set = housing_with_idx.loc[test_index]\n",
    "        \n",
    "print(\"train set shape: \", strat_train_set.shape)\n",
    "print(\"test set shape: \", strat_test_set.shape)\n",
    "print(strat_test_set['city_b'].value_counts() / len(strat_test_set))\n",
    "print(housing_with_idx['city_b'].value_counts() / len(housing_with_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d3c7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "setA = set(sel_num_housing)\n",
    "removed_on_the_go = [\"propertyValuation_b\", \"paymentCash_b\", \"AVM_pris_d\", 'alfs_postal',\n",
    "                     'priceChangeYPriorIndex_s', 'longitude_b', 'latitude_b', 'Antal Etager', #What remove this round\n",
    "                     'WaterHardness', 'quarter0_b', 'city_b', 'Opførselsesår', \"itemTypeName_b\", 'itemtypeName',\n",
    "                     \"Bygning, Samlet areal\", 'areaResidential_b', \n",
    "                     'unemploymentRateDK_s', 'priceChangeYPriorIndex_s', 'alfs_buildYear_d',\n",
    "                     'kitchen.content_d', 'heating_d', 'electionArea_d']\n",
    "# Get new set with elements that are only in a but not in b\n",
    "updated_sel_num = setA.difference(removed_on_the_go)\n",
    "\n",
    "setB = set(cat_features)\n",
    "updated_cat_feat = setB.difference(removed_on_the_go)\n",
    "\n",
    "\n",
    "drop_features = DropFeatureSelector(variables = removed_features + removed_on_the_go)\n",
    "num_feature_selector = FeatureSelector(variables = updated_sel_num) # + [\"city_b\"])# to make boxplot\n",
    "cat_feature_selector = FeatureSelector(variables = updated_cat_feat)\n",
    "num_paymentAttributesAdder = paymentAttributesAdder(variables = [\"salePrice_b\"])\n",
    "num_interiorAttributesAdder = interiorAttributesAdder2(variables = inter_vars2)\n",
    "num_rebuildYearAttributesAdder = rebuildYearAttributesAdder(variables = rebuild_vars)\n",
    "num_datetimeAttributesAdder = datetimeAttributesAdder(variables = salePeriod_vars)\n",
    "\n",
    "num_StandardScalercustom = StandardScalercustom(variables = 'salePrice_b' )\n",
    "\n",
    "\n",
    "#outlier_vars = ['salePrice_b']\n",
    "#num_outlier_remover = OutlierRemover(variables = outlier_vars)\n",
    "outlier_vars2 = ['salePrice_b', 'alfs_area']\n",
    "num_outlier_remover = OutlierRemover2(variables = outlier_vars2, factor = 0.05)\n",
    "\n",
    "\n",
    "cat_postalAttributesAdder = postalAttributesAdder(variables = postal_vars)\n",
    "cat_energyAttributesAdder = energyAttributesAdder(variables = energy_vars)\n",
    "cat_usageAttributesAdder = usageAttributesAdder(variables = usage_vars)\n",
    "cat_rnfbAttributesAdder = rnfbAttributesAdder(variables = rnfb_vars)\n",
    "cat_most_frequent_imputer = SimpleImputerCustom(variables = [#'kitchen.content_d',\n",
    "                                                             'outerwall_d',\n",
    "                                                             'roof_d'], \n",
    "                                                strategy = 'most_frequent')\n",
    "\n",
    "\n",
    "onehot_housing_2 = ['postalId_b', 'usage_d', 'outerwall_d', 'roof_d', \n",
    "                    'biggestParty_d']\n",
    "\n",
    "cat_OneHotEncodercustom = OneHotEncodercustom(variables = onehot_housing_2)\n",
    "ord_housing_2 = ['noise_d', 'energyMark_b', \n",
    "                'radonRisk_d', 'floodingRisk_d',\n",
    "                'quarter_b']\n",
    "cat_OrdinalEncodercustom = OrdinalEncodercustom(variables = ord_housing_2)\n",
    "\n",
    "\n",
    "rare_encoder = encoding.RareLabelEncoder(tol=0.015, n_categories=2,\n",
    "                    variables=['outerwall_d', 'roof_d'], replace_with='rare') ### This one is added\n",
    "\n",
    "\n",
    "complete_drop_nans = FunctionTransformer(drop_nans, validate=False)\n",
    "\n",
    "num_preprocessing_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('drop_features', drop_features),\n",
    "        (\"num_feature_selector\", num_feature_selector),\n",
    "        ('interiorAttributesAdder', num_interiorAttributesAdder),\n",
    "        ('rebuildYearAttributesAdder', num_rebuildYearAttributesAdder),\n",
    "        ('datetimeAttributesAdder', num_datetimeAttributesAdder),   \n",
    "        ('paymentAttributesAdder', num_paymentAttributesAdder),\n",
    "        ('num_outlier_remover', num_outlier_remover),\n",
    "        ('StandardScalercustom', num_StandardScalercustom)   \n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_preprocessing_pipe = Pipeline(steps=[\n",
    "    ('drop_features', drop_features),\n",
    "    (\"cat_feature_selector\", cat_feature_selector),\n",
    "    #('itemAttributesAdder', cat_itemAttributesAdder),    \n",
    "    (\"postalAttributesAdder\", cat_postalAttributesAdder),\n",
    "    (\"energyAttributesAdder\", cat_energyAttributesAdder),\n",
    "    (\"usageAttributesAdder\", cat_usageAttributesAdder),\n",
    "    (\"rnfbAttributesAdder\", cat_rnfbAttributesAdder),\n",
    "    #(\"cat_most_frequent_imputer\", cat_most_frequent_imputer) #Trying without\n",
    "    \n",
    "])\n",
    "\n",
    "combined_preprocessing = FeatureUnion([\n",
    "    ('numericals', num_preprocessing_pipe),\n",
    "    ('categoricals', cat_preprocessing_pipe)\n",
    "])\n",
    "\n",
    "num_features_col = list(num_preprocessing_pipe.fit_transform(strat_train_set).columns)\n",
    "cat_features_col = list(cat_preprocessing_pipe.fit_transform(strat_train_set).columns)\n",
    "Make_dataframe = MakeToDataFrame(num_features_col + cat_features_col)\n",
    "\n",
    "complete_pipeline = Pipeline([\n",
    "    ('preprocessing', combined_preprocessing),\n",
    "    ('complete_drop_nans', complete_drop_nans),\n",
    "    ('DataFrame_maker', Make_dataframe),\n",
    "    ('ohe_rare_encoder', rare_encoder),\n",
    "    (\"cat_OneHotEncodercustom\", cat_OneHotEncodercustom),\n",
    "    (\"cat_OrdinalEncodercustom\", cat_OrdinalEncodercustom),\n",
    "    ('To_make_array', complete_drop_nans)\n",
    "    \n",
    "])\n",
    "\n",
    "housing_data_pre_pipe = complete_pipeline.fit_transform(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d17f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e44b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2154452.30783213 3554293.41718087 5433388.22905581 ... 5829611.5385097\n",
      " 1299476.03752258 5568912.03494655]\n",
      "Label-values: [1685000. 3625000. 5900000. ... 5000000. 1545000. 5300000.]\n",
      "Linear rmse: 620115.9670585608\n",
      "Absolute loss: 427350.1109731169\n",
      "Relative loss: 0.11584419875601101\n"
     ]
    }
   ],
   "source": [
    "Find_salePrice = 0 #It is the first because of how custom std scaler works\n",
    "\n",
    "reg_data = complete_pipeline.transform(strat_train_set)\n",
    "\n",
    "pre_y = reg_data[:,Find_salePrice].astype(float)\n",
    "pre_X = np.delete(reg_data, obj = Find_salePrice , axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(pre_X, pre_y)\n",
    "\n",
    "\n",
    "housing_predictions = lin_reg.predict(pre_X)\n",
    "lin_mse = mean_squared_error(pre_y, housing_predictions)\n",
    "\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"Predictions:\", lin_reg.predict(pre_X))\n",
    "print(\"Label-values:\", pre_y)\n",
    "print(\"Linear rmse:\", lin_rmse)\n",
    "print(\"Absolute loss:\", mean_absolute_error(pre_y, housing_predictions))\n",
    "print(\"Relative loss:\", mean_absolute_percentage_error(pre_y, lin_reg.predict(pre_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210a69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
